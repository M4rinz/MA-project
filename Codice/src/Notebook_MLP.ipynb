{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e51947e",
   "metadata": {},
   "source": [
    "# Backpropagation through Back substitution with a Backslash\n",
    "Notebook per il seminario d'esame per il corso di Metodi di Approssimazione "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039c898d",
   "metadata": {},
   "source": [
    "## Algebra degli operatori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f05474",
   "metadata": {},
   "source": [
    "Definiamo il tipo di dato custom che rappresenta la funzione lineare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad5d93f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ğ’ª (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "struct Operator  # Linear Matrix Operators from Matrices to Matrices (and the operator adjoint)\n",
    "    op\n",
    "    adj\n",
    "    sym\n",
    "end\n",
    "\n",
    "## Operators\n",
    "â„’(A::Matrix)  = Operator(X->A*X   , X->A'*X, \"â„’$(size(A))\"  )   # left multiply by A (X â†’ AX)\n",
    "â„›(A::Matrix)  = Operator(X->X*A   , X->X*A', \"â„›$(size(A))\")     # right multiply by A (X â†’ XA)\n",
    "â„‹(A::Matrix)  = Operator(X->X.*A  , X->X.*A, \"â„‹$(size(A))\")    # Hadamard product (elementwise product)\n",
    "â„()  =          Operator(X->X      ,    X->X,    \"I\")     # identity operator\n",
    "ğ’ª()  =           Operator(X->zero(X) , X->zero(X),\"ğ’ª\")# zero operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2451af2e",
   "metadata": {},
   "source": [
    "Dobbiamo anche fare *overloading* delle operazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "858f8906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+ (generic function with 192 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import Base:  zero, show, adjoint, *, \\, âˆ˜, +, -\n",
    "show(io::IO, M::Operator) = print(io, M.sym)  # pretty printing\n",
    "zero(::Any) = ğ’ª() # Let's make any undefined zero the ğ’ª operator\n",
    "\n",
    "adjoint(A::Operator) = Operator(A.adj, A.op,  \"(\"*A.sym*\")'\")\n",
    "adjoint(B::Bidiagonal) = Bidiagonal(adjoint.(B.dv),adjoint.(B.ev),(B.uplo == 'U') ? :L : :U) # lower to upper\n",
    "\n",
    "-(A::Operator) = Operator(X->-A.op(X), X->-A.adj(X),\"-\"*A.sym)\n",
    "-(::typeof(ğ’ª()), X::Matrix) = -X  # ğ’ª() - X should be -X\n",
    "\\(â„::typeof(â„()), A::Matrix) = A    # left division with â„() does nothing\n",
    "*(A::Operator, X::Matrix) = A.op(X)\n",
    "âˆ˜(A::Operator, B::Operator) = Operator(A.op âˆ˜ B.op, B.adj âˆ˜ A.adj, A.sym*\"âˆ˜\"*B.sym)\n",
    "# We need [A;B]*C to somehow magically be [AC;BC]\n",
    "*(M::Adjoint{Operator, Matrix{Operator}},v::Array) = M .* [v]\n",
    "+(A::Array,x::Number)=A.+x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6937b54d",
   "metadata": {},
   "source": [
    "## Una semplice rete neurale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2b4d9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_net (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using OffsetArrays\n",
    "\n",
    "# funzione di attivazione\n",
    "h(x)  = tanh(x)\n",
    "hâ€²(x) = 1 - h(x)^2\n",
    "\n",
    "\n",
    "# questa funzione, di fatto, effettua il forward pass\n",
    "function neural_net(params,Xâ‚€;h=h,hâ€²= hâ€²)\n",
    "    T = Matrix{Float64}\n",
    "    N = length(params)\n",
    "    X = OffsetArray(Vector{T}(undef,N+1),0:N)   \n",
    "    Î” = Vector{T}(undef, N)\n",
    "    X[0] = Xâ‚€\n",
    "    W = first.(params)\n",
    "    B = last.(params)\n",
    "    \n",
    "    for i=1:N         \n",
    "          X[i] =  h.(W[i]*X[i-1] .+ B[i])\n",
    "          Î”[i] =  hâ€².(W[i]*X[i-1] .+ B[i])        \n",
    "    end \n",
    "    X,Î”\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be84c70",
   "metadata": {},
   "source": [
    "Adesso possiamo costruire la rete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b034015b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Un po' di parametri che descrivono la rete...\n",
    "\n",
    "n = [5,4,3,1]   # contiene [nâ‚€...n_N], le dimensioni dei layer\n",
    "k = 10          # batchsize\n",
    "N = length(n)-1 # numero di layer (nascosti + output). Dev'essere positivo\n",
    "\n",
    "init(sizes...) = 0.01randn(sizes...)    # utility function per inizializzare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "621fdcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[-0.0016417890745344186 -0.009017347211780685 â€¦ 0.0025201846228055233 -0.005976180522108683; -0.006524349957957305 0.006668125733105701 â€¦ -0.001309900513298213 -0.011214868952770391; â€¦ ; 0.009675829835573083 0.005185615908738407 â€¦ 0.00448176661371606 -0.008001887746487812; -0.0006842970624141817 -0.01434530203871462 â€¦ 0.01449309417043186 0.026235373996079652], [-0.0035950161387576906 -0.0037450840253618186 â€¦ -0.0038194347346536457 -0.0034255935748631556; 0.001479865885599661 0.0011574033454949788 â€¦ 0.0014576388765281478 0.0012374923073648122; 0.004662760313738267 0.004699608816944095 â€¦ 0.004364163082760891 0.00432361808896052; -0.001092758455435424 -0.0008530184413698413 â€¦ -0.0013226168609899868 -0.0011771650889709278], [-0.0010305072324071163 -0.0010310707137579532 â€¦ -0.0010389906484406792 -0.0010339513011064557; 0.012250733425353719 0.012248764345552322 â€¦ 0.01224982871517388 0.012251318577506318; -0.004634072369190367 -0.004626532936839199 â€¦ -0.0046365253698575385 -0.004634337143342055], [0.001364277866802935 0.001364365578003799 â€¦ 0.001364249653217699 0.0013642862347964045]], [[0.9999870758589621 0.999985974345643 â€¦ 0.9999854119183077 0.9999882653086598; 0.9999978099969606 0.9999986604174959 â€¦ 0.9999978752889056 0.9999984686127892; 0.9999782586662567 0.9999779136769678 â€¦ 0.9999809540805871 0.9999813063266209; 0.9999988058789581 0.9999992723595387 â€¦ 0.999998250684639 0.9999986142823533], [0.999998938054844 0.9999989368931832 â€¦ 0.9999989204984324 0.9999989309447069; 0.9998499195305409 0.9998499677720071 â€¦ 0.9998499416964489 0.9998499051931125; 0.9999785253732771 0.9999785951929844 â€¦ 0.9999785026324947 0.9999785229192418], [0.9999981387459022 0.9999981385065696 â€¦ 0.9999981388228837 0.9999981387230695]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Un po' di parametri degni di questo nome\n",
    "\n",
    "# Creiamo le matrici dei pesi e i vettori dei bias\n",
    "Ws_and_bs =[ [init(n[i+1],n[i]) , init(n[i+1])]  for i=1:N] # The second part of the pair is a vector here\n",
    "\n",
    "Xâ‚€ = init(n[1],k)         # batch di k pattern (aka i dati)\n",
    "y  = init(n[end],k);      # y is what we will compare X_N against (aka l'etichetta)\n",
    "\n",
    "ğ“(x,y)  = sum(abs2,x-y)/2   # loss (errore quadratico)\n",
    "ğ“â€²(x,y) = x .- y;           # derivata della loss (w.r.t. output layer)\n",
    "\n",
    "X, Î´ = neural_net(Ws_and_bs,Xâ‚€) # Inferenza (aka forward pass)\n",
    "# X e Î´ hanno i valori per ogni layer (servono per fare il backward pass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5675bf2f",
   "metadata": {},
   "source": [
    "Adesso possiamo calcolare il gradiente della loss usando la nostra tecnica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd9adda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Matrix{Matrix{Float64}}}:\n",
       " [[1.4088127013625462e-8 -6.147652480622261e-9 â€¦ 1.4816419312868407e-8 -2.5388932382734446e-8; 1.0140479781016571e-7 -4.4250211946458045e-8 â€¦ 1.0664677341123823e-7 -1.8274649895991573e-7; -5.097415279758743e-8 2.2243637685757134e-8 â€¦ -5.3609164969686924e-8 9.186308901637223e-8; -1.3074494685783658e-8 5.7053466945935386e-9 â€¦ -1.3750373031774129e-8 2.3562181295239357e-8]; [-2.472493766068718e-7; -1.779680410303707e-6; 8.946151060642498e-7; 2.2945975531540416e-7;;];;]\n",
       " [[5.1684687361671e-8 6.358938748516488e-9 -4.773460222810447e-8 1.630541229054533e-8; -2.8385966094942884e-7 -3.492418946061795e-8 2.621652361170077e-7 -8.955164381597129e-8; -4.0106900857663703e-7 -4.934481338688734e-8 3.704166924592903e-7 -1.2652868134864764e-7]; [-1.4484995052276062e-5; 7.955365450264909e-5; 0.00011240239326399518;;];;]\n",
       " [[-8.376357555014538e-6 9.761445816787112e-5 -3.6788071913389015e-5]; [0.007968857159263123;;];;]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## The diagonal matrix\n",
    "#M = Diagonal([ [â„‹(Î´[i]) âˆ˜ â„›(X[i-1])  â„‹(Î´[i])] for i=1:N]) # OLD!\n",
    "M = Diagonal([ [â„‹(Î´[i]) âˆ˜ â„›(X[i-1])  â„‹(Î´[i]) âˆ˜ â„›(ones(1,k))] for i=1:N])\n",
    "\n",
    "## The lower triangular matrix (I-L)\n",
    "ImL = Bidiagonal([â„() for i in 1:N], -[â„‹(Î´[i]) âˆ˜ â„’(Ws_and_bs[i][1]) for i=2:N] , :L)\n",
    "\n",
    "## derivata della loss (rispetto all'output layer)\n",
    "g = [ fill(ğ’ª(),N-1) ; [ğ“â€²(X[N],y)] ]      \n",
    "\n",
    "## Finalmente, il gradiente della loss, usando il backslash\n",
    "âˆ‡J = M' * (ImL' \\ g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cc58cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âˆ‡J[1]\n",
      "\tTipo: Matrix{Matrix{Float64}}\t size: (2, 1)\n",
      "\t\tâˆ‡J[1][1] ha dimensione (4, 5), e n_1 x n_0 = 4x5. Tipo Matrix{Float64}\n",
      "\t\tâˆ‡J[1][2] ha dimensione (4, 1), e n_1 \t   = 4.   Tipo Matrix{Float64}\n",
      "\n",
      "âˆ‡J[2]\n",
      "\tTipo: Matrix{Matrix{Float64}}\t size: (2, 1)\n",
      "\t\tâˆ‡J[2][1] ha dimensione (3, 4), e n_2 x n_1 = 3x4. Tipo Matrix{Float64}\n",
      "\t\tâˆ‡J[2][2] ha dimensione (3, 1), e n_2 \t   = 3.   Tipo Matrix{Float64}\n",
      "\n",
      "âˆ‡J[3]\n",
      "\tTipo: Matrix{Matrix{Float64}}\t size: (2, 1)\n",
      "\t\tâˆ‡J[3][1] ha dimensione (1, 3), e n_3 x n_2 = 1x3. Tipo Matrix{Float64}\n",
      "\t\tâˆ‡J[3][2] ha dimensione (1, 1), e n_3 \t   = 1.   Tipo Matrix{Float64}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i=1:N\n",
    "    print(\"âˆ‡J[$i]\\n\")\n",
    "    print(\"\\tTipo: $(typeof(âˆ‡J[i]))\\t size: $(size(âˆ‡J[i]))\\n\")\n",
    "    print(\"\\t\\tâˆ‡J[$i][1] ha dimensione $(size(âˆ‡J[i][1])), e n_$(i) x n_$(i-1) = $(n[i+1])x$(n[i]). Tipo $(typeof(âˆ‡J[i][1]))\\n\")\n",
    "    print(\"\\t\\tâˆ‡J[$i][2] ha dimensione $(size(âˆ‡J[i][2])), e n_$(i) \\t   = $(n[i+1]).   Tipo $(typeof(âˆ‡J[i][2]))\\n\")\n",
    "    print(\"\\n\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a491fb",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fce4328",
   "metadata": {},
   "source": [
    "Calcoliamo il gradiente usando il metodo delle differenze finite, per controllare il risultato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20933c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#âˆ‡Jfd is the gradient calculated with finite differences method\n",
    "\n",
    "# creiamo uno zero della stessa dimensione del gradiente\n",
    "âˆ‡Jfd = Ws_and_bs*0\n",
    "Ïµ = Ws_and_bs*0\n",
    "ğœ€ = .0001\n",
    "for i=1:length(Ws_and_bs), wb=1:2\n",
    "    for j=1:length(Ïµ[i][wb])    \n",
    "        Ïµ[i][wb][j] = ğœ€\n",
    "        # Derivata direzionale approssimata con differenze finite\n",
    "        âˆ‡Jfd[i][wb][j] = (ğ“(neural_net(Ws_and_bs+Ïµ,Xâ‚€)[1][N],y) .- ğ“(neural_net(Ws_and_bs-Ïµ,Xâ‚€)[1][N],y))/2ğœ€\n",
    "        Ïµ[i][wb][j] = .0\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0156165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âˆ‡Jfd[1]\n",
      "\tTipo: Vector{Array{Float64}}\t size: (2,)\n",
      "\t\tâˆ‡Jfd[1][1] ha dimensione (4, 5), e n_1 x n_0 = 4x5. Tipo Matrix{Float64}\n",
      "\t\tâˆ‡Jfd[1][2] ha dimensione (4,)  , e n_1 \t     = 4.   Tipo Vector{Float64}\n",
      "\n",
      "âˆ‡Jfd[2]\n",
      "\tTipo: Vector{Array{Float64}}\t size: (2,)\n",
      "\t\tâˆ‡Jfd[2][1] ha dimensione (3, 4), e n_2 x n_1 = 3x4. Tipo Matrix{Float64}\n",
      "\t\tâˆ‡Jfd[2][2] ha dimensione (3,)  , e n_2 \t     = 3.   Tipo Vector{Float64}\n",
      "\n",
      "âˆ‡Jfd[3]\n",
      "\tTipo: Vector{Array{Float64}}\t size: (2,)\n",
      "\t\tâˆ‡Jfd[3][1] ha dimensione (1, 3), e n_3 x n_2 = 1x3. Tipo Matrix{Float64}\n",
      "\t\tâˆ‡Jfd[3][2] ha dimensione (1,)  , e n_3 \t     = 1.   Tipo Vector{Float64}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i=1:N\n",
    "    print(\"âˆ‡Jfd[$i]\\n\")\n",
    "    print(\"\\tTipo: $(typeof(âˆ‡Jfd[i]))\\t size: $(size(âˆ‡Jfd[i]))\\n\")\n",
    "    print(\"\\t\\tâˆ‡Jfd[$i][1] ha dimensione $(size(âˆ‡Jfd[i][1])), e n_$(i) x n_$(i-1) = $(n[i+1])x$(n[i]). Tipo $(typeof(âˆ‡Jfd[i][1]))\\n\")\n",
    "    print(\"\\t\\tâˆ‡Jfd[$i][2] ha dimensione $(size(âˆ‡Jfd[i][2]))  , e n_$(i) \\t     = $(n[i+1]).   Tipo $(typeof(âˆ‡Jfd[i][2]))\\n\")\n",
    "    print(\"\\n\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c01f3b",
   "metadata": {},
   "source": [
    "Interessante notare un leggero mismatch di tipi tra `âˆ‡J` e `âˆ‡Jfd`, ma restano compatibili. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b298ae79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flatten (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# flatten(J) = vcat((x->x[:]).(vcat(J...))...)\n",
    "\n",
    "function flatten(J) \n",
    "    # create a 2N x 1 matrix of matrices [Wâ‚; Bâ‚; ... Wâ‚™]\n",
    "    stackedWandB = vcat(J...)       # this is a Matrix{Matrix{Float64}}\n",
    "    # flatten out the matrices inside the stack\n",
    "    unstackedStack = (x->x[:]).(stackedWandB)   # this is a Matrix{Vector{Float64}}\n",
    "\n",
    "    # stack all the vectors that are in the `unstackedStack` matrix\n",
    "    return vcat(unstackedStack...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "469f49cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6298909507136707e-10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "norm(flatten(âˆ‡J)-flatten(âˆ‡Jfd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acb135d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.044840802928026e-8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "norm(flatten(âˆ‡J)-flatten(âˆ‡Jfd)) / norm(flatten(âˆ‡J))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8c1c4c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e2f9a82",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8f1ff64",
   "metadata": {},
   "source": [
    "## Errori, e problemi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b243bfc2",
   "metadata": {},
   "source": [
    "### In generale, moltiplicazione tra matrici di operatori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bbb5e4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ef6035",
   "metadata": {},
   "source": [
    "### Moltiplicare matrici di operatori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4075ac",
   "metadata": {},
   "source": [
    "E' possibile moltiplicare ($\\equiv$ comporre) matrici di operatori, usando le regole a nostra disposizione? E eventualmente aggiungendone di nuove?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed9d2a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3Ã—3 Diagonal{Operator, Vector{Operator}}:\n",
       " â„‹(4, 10)âˆ˜â„›(5, 10)  â‹…                  â‹…\n",
       " â‹…                  â„‹(3, 10)âˆ˜â„›(4, 10)  â‹…\n",
       " â‹…                  â‹…                  â„‹(1, 10)âˆ˜â„›(3, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Mnuova = Diagonal([â„‹(Î´[i]) âˆ˜ â„›(X[i-1]) for i=1:N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6782f45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3Ã—3 Bidiagonal{Operator, Vector{Operator}}:\n",
       " Iâˆ˜â„‹(4, 10)âˆ˜â„›(5, 10)                  â€¦  â‹…\n",
       " -â„‹(3, 10)âˆ˜â„’(3, 4)âˆ˜â„‹(4, 10)âˆ˜â„›(5, 10)     â‹…\n",
       " â‹…                                       Iâˆ˜â„‹(1, 10)âˆ˜â„›(3, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try\n",
    "    ImL * Mnuova\n",
    "catch e\n",
    "    showerror(stdout, e)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d40f06c",
   "metadata": {},
   "source": [
    "Come glielo spieghiamo che quell'elemento lÃ¬ in realtÃ  Ã¨ zero??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e4e1bc",
   "metadata": {},
   "source": [
    "**AGGIUSTARE**: Dando le martellate giuste, qualcosa si puÃ² fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79c2ff10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "* (generic function with 191 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "*(A::Operator, B::Operator) = A âˆ˜ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5ee7d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+ (generic function with 193 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "+(A::Operator, B::Operator) = Operator(X->(A.op(X) + B.op(X)), X->(A.adj(X) + B.adj(X)), A.sym*\" + \"*B.sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63879d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3Ã—3 Matrix{Operator}:\n",
       " ğ’ªâˆ˜ğ’ª + ğ’ªâˆ˜ğ’ª + Iâˆ˜â„‹(4, 10)âˆ˜â„›(5, 10) + ğ’ª                  â€¦  ğ’ªâˆ˜â„‹(1, 10)âˆ˜â„›(3, 10) + ğ’ªâˆ˜ğ’ª + Iâˆ˜ğ’ª + ğ’ª\n",
       " ğ’ªâˆ˜ğ’ª + Iâˆ˜ğ’ª + -â„‹(3, 10)âˆ˜â„’(3, 4)âˆ˜â„‹(4, 10)âˆ˜â„›(5, 10) + ğ’ª     ğ’ªâˆ˜â„‹(1, 10)âˆ˜â„›(3, 10) + Iâˆ˜ğ’ª + -â„‹(3, 10)âˆ˜â„’(3, 4)âˆ˜ğ’ª + ğ’ª\n",
       " Iâˆ˜ğ’ª + -â„‹(1, 10)âˆ˜â„’(1, 3)âˆ˜ğ’ª + ğ’ªâˆ˜â„‹(4, 10)âˆ˜â„›(5, 10) + ğ’ª     Iâˆ˜â„‹(1, 10)âˆ˜â„›(3, 10) + -â„‹(1, 10)âˆ˜â„’(1, 3)âˆ˜ğ’ª + ğ’ªâˆ˜ğ’ª + ğ’ª"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Matrix(ImL) * Matrix(Mnuova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6aae243",
   "metadata": {},
   "outputs": [
    {
     "ename": "DimensionMismatch",
     "evalue": "DimensionMismatch: incompatible dimensions for matrix multiplication: tried to multiply a matrix of size (3, 4) with a matrix of size (1, 2). The second dimension of the first matrix: 4, does not match the first dimension of the second matrix: 1.",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch: incompatible dimensions for matrix multiplication: tried to multiply a matrix of size (3, 4) with a matrix of size (1, 2). The second dimension of the first matrix: 4, does not match the first dimension of the second matrix: 1.\n",
      "\n",
      "Stacktrace:\n",
      "  [1] matmul_size_check_error(sizeA::Tuple{Int64, Int64}, sizeB::Tuple{Int64, Int64})\n",
      "    @ LinearAlgebra ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:431\n",
      "  [2] matmul_size_check\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:418 [inlined]\n",
      "  [3] matmul_size_check\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:441 [inlined]\n",
      "  [4] _generic_matmatmul!(C::Matrix{Union{}}, A::Matrix{Float64}, B::Matrix{Operator}, alpha::Bool, beta::Bool)\n",
      "    @ LinearAlgebra ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:1018\n",
      "  [5] generic_matmatmul!\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:1009 [inlined]\n",
      "  [6] generic_matmatmul_wrapper!\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:343 [inlined]\n",
      "  [7] _mul!\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:328 [inlined]\n",
      "  [8] mul!\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:297 [inlined]\n",
      "  [9] mul!\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:265 [inlined]\n",
      " [10] mul\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:118 [inlined]\n",
      " [11] *\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:114 [inlined]\n",
      " [12] #â„’##0\n",
      "    @ ~/Scrivania/MA-project/Codice/src/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W3sZmlsZQ==.jl:10 [inlined]\n",
      " [13] call_composed\n",
      "    @ ./operators.jl:1100 [inlined]\n",
      " [14] call_composed\n",
      "    @ ./operators.jl:1099 [inlined]\n",
      " [15] (::ComposedFunction{var\"#â„‹##0#â„‹##1\"{Matrix{Float64}}, var\"#â„’##0#â„’##1\"{Matrix{Float64}}})(x::Matrix{Operator}; kw::@Kwargs{})\n",
      "    @ Base ./operators.jl:1096\n",
      " [16] (::var\"#-##0#-##1\"{Operator})(X::Matrix{Operator})\n",
      "    @ Main ~/Scrivania/MA-project/Codice/src/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W5sZmlsZQ==.jl:8\n",
      " [17] *(A::Operator, X::Matrix{Operator})\n",
      "    @ Main ~/Scrivania/MA-project/Codice/src/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W5sZmlsZQ==.jl:11\n",
      " [18] _mul!(C::Bidiagonal{Any, Vector{Any}}, A::Bidiagonal{Operator, Vector{Operator}}, B::Diagonal{Matrix{Operator}, Vector{Matrix{Operator}}}, _add::LinearAlgebra.MulAddMul{true, true, Bool, Bool})\n",
      "    @ LinearAlgebra ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/bidiag.jl:920\n",
      " [19] macro expansion\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/generic.jl:100 [inlined]\n",
      " [20] _mul!\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/bidiag.jl:831 [inlined]\n",
      " [21] mul!\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:297 [inlined]\n",
      " [22] mul!\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:265 [inlined]\n",
      " [23] mul\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:118 [inlined]\n",
      " [24] *(A::Bidiagonal{Operator, Vector{Operator}}, B::Diagonal{Matrix{Operator}, Vector{Matrix{Operator}}})\n",
      "    @ LinearAlgebra ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:114\n",
      " [25] top-level scope\n",
      "    @ ~/Scrivania/MA-project/Codice/src/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y210sZmlsZQ==.jl:1"
     ]
    }
   ],
   "source": [
    "ImL * M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "534fdf8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.12.4",
   "language": "julia",
   "name": "julia-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
