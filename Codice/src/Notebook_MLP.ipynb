{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e51947e",
   "metadata": {},
   "source": [
    "# Backpropagation through Back substitution with a Backslash\n",
    "Notebook per il seminario d'esame per il corso di Metodi di Approssimazione "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039c898d",
   "metadata": {},
   "source": [
    "## Algebra degli operatori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f05474",
   "metadata": {},
   "source": [
    "Definiamo il tipo di dato custom che rappresenta la funzione lineare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad5d93f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ğ’ª (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "struct Operator  # Linear Matrix Operators from Matrices to Matrices (and the operator adjoint)\n",
    "    op\n",
    "    adj\n",
    "    sym\n",
    "end\n",
    "\n",
    "## Operators\n",
    "â„’(A::Matrix)  = Operator(X->A*X   , X->A'*X, \"â„’$(size(A))\"  )   # left multiply by A (X â†’ AX)\n",
    "â„›(A::Matrix)  = Operator(X->X*A   , X->X*A', \"â„›$(size(A))\")     # right multiply by A (X â†’ XA)\n",
    "â„‹(A::Matrix)  = Operator(X->X.*A  , X->X.*A, \"â„‹$(size(A))\")    # Hadamard product (elementwise product)\n",
    "â„()  =          Operator(X->X      ,    X->X,    \"I\")     # identity operator\n",
    "ğ’ª()  =           Operator(X->zero(X) , X->zero(X),\"ğ’ª\")# zero operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2451af2e",
   "metadata": {},
   "source": [
    "Dobbiamo anche fare *overloading* delle operazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "858f8906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+ (generic function with 192 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import Base:  zero, show, adjoint, *, \\, âˆ˜, +, -\n",
    "show(io::IO, M::Operator) = print(io, M.sym)  # pretty printing\n",
    "zero(::Any) = ğ’ª() # Let's make any undefined zero the ğ’ª operator\n",
    "\n",
    "adjoint(A::Operator) = Operator(A.adj, A.op,  \"(\"*A.sym*\")'\")\n",
    "adjoint(B::Bidiagonal) = Bidiagonal(adjoint.(B.dv),adjoint.(B.ev),(B.uplo == 'U') ? :L : :U) # lower to upper\n",
    "\n",
    "-(A::Operator) = Operator(X->-A.op(X), X->-A.adj(X),\"-\"*A.sym)\n",
    "-(::typeof(ğ’ª()), X::Matrix) = -X  # ğ’ª() - X should be -X\n",
    "\\(â„::typeof(â„()), A::Matrix) = A    # left division with â„() does nothing\n",
    "*(A::Operator, X::Matrix) = A.op(X)\n",
    "âˆ˜(A::Operator, B::Operator) = Operator(A.op âˆ˜ B.op, B.adj âˆ˜ A.adj, A.sym*\"âˆ˜\"*B.sym)\n",
    "# We need [A;B]*C to somehow magically be [AC;BC]\n",
    "*(M::Adjoint{Operator, Matrix{Operator}},v::Array) = M .* [v]\n",
    "+(A::Array,x::Number)=A.+x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6937b54d",
   "metadata": {},
   "source": [
    "## Una semplice rete neurale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2b4d9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_net (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using OffsetArrays\n",
    "\n",
    "# funzione di attivazione\n",
    "h(x)  = tanh(x)\n",
    "hâ€²(x) = 1 - h(x)^2\n",
    "\n",
    "\n",
    "# questa funzione, di fatto, effettua il forward pass\n",
    "function neural_net(params,Xâ‚€;h=h,hâ€²= hâ€²)\n",
    "    T = Matrix{Float64}\n",
    "    N = length(params)\n",
    "    X = OffsetArray(Vector{T}(undef,N+1),0:N)   \n",
    "    Î” = Vector{T}(undef, N)\n",
    "    X[0] = Xâ‚€\n",
    "    W = first.(params)\n",
    "    B = last.(params)\n",
    "    \n",
    "    for i=1:N         \n",
    "          X[i] =  h.(W[i]*X[i-1] .+ B[i])\n",
    "          Î”[i] =  hâ€².(W[i]*X[i-1] .+ B[i])        \n",
    "    end \n",
    "    X,Î”\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be84c70",
   "metadata": {},
   "source": [
    "Adesso possiamo costruire la rete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b034015b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Un po' di parametri che descrivono la rete...\n",
    "\n",
    "n = [5,4,3,1]   # contiene [nâ‚€...n_N], le dimensioni dei layer\n",
    "k = 10          # batchsize\n",
    "N = length(n)-1 # numero di layer (nascosti + output). Dev'essere positivo\n",
    "\n",
    "init(sizes...) = 0.01randn(sizes...)    # utility function per inizializzare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "621fdcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[-0.0038920596274483023 -0.006279812952603613 â€¦ -0.017758504443525884 0.004667387128659968; 0.015942179536630473 0.012570888512030568 â€¦ 0.01371093918177978 -0.004376016958212193; â€¦ ; -0.004876053489589111 -0.0053377709119724615 â€¦ 0.006703462932380859 -0.001993766218737081; 0.004328717464026433 -0.02822612573031091 â€¦ 0.005971523297016189 0.00979093132937066], [0.0006922505541532706 0.0004375130585479821 â€¦ 0.0003690441783070967 0.000772497883546509; 0.0025324123351055075 0.0030502401659387884 â€¦ 0.002670290594542111 0.002605251236228453; 0.010599262633185908 0.010263579315659264 â€¦ 0.010482523747786928 0.010725799325388485; 0.004615310341560691 0.0047452061376692615 â€¦ 0.004942921912003799 0.004541298653022729], [0.008963047232478157 0.008958803433999367 â€¦ 0.008962178437286857 0.008962599581076211; -0.009303041646536014 -0.009298023256166563 â€¦ -0.009299818583119509 -0.009303261575996927; 0.001034564510214828 0.0010303309107956291 â€¦ 0.001032601031091371 0.0010352088322960749], [-0.0037644905036363233 -0.003764592466713896 â€¦ -0.00376452198625065 -0.00376450354874703]], [[0.9999995207891703 0.9999998085823236 â€¦ 0.9999998638063945 0.99999940324702; 0.999993586887765 0.9999906960349301 â€¦ 0.9999928695481407 0.9999932126659962; 0.9998876556316327 0.9998946589396311 â€¦ 0.9998901166958771 0.9998849572288315; 0.9999786989104511 0.999977483018711 â€¦ 0.9999755675229718 0.999979376606544], [0.9999196637843084 0.999919739841031 â€¦ 0.9999196793576582 0.9999196718087493; 0.9999134534161228 0.9999135467635278 â€¦ 0.9999135133743211 0.9999134493240486; 0.9999989296762742 0.9999989384182143 â€¦ 0.9999989337351106 0.9999989283426736], [0.9999858286112481 0.9999858278435596 â€¦ 0.999985828374215 0.9999858285130314]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Un po' di parametri degni di questo nome\n",
    "\n",
    "# Creiamo le matrici dei pesi e i vettori dei bias\n",
    "Ws_and_bs =[ [init(n[i+1],n[i]) , init(n[i+1])]  for i=1:N] # The second part of the pair is a vector here\n",
    "\n",
    "Xâ‚€ = init(n[1],k)         # batch di k pattern (aka i dati)\n",
    "y  = init(n[end],k);      # y is what we will compare X_N against (aka l'etichetta)\n",
    "\n",
    "ğ“(x,y)  = sum(abs2,x-y)/2   # loss (errore quadratico)\n",
    "ğ“â€²(x,y) = x .- y;           # derivata della loss (w.r.t. output layer)\n",
    "\n",
    "X, Î´ = neural_net(Ws_and_bs,Xâ‚€) # Inferenza (aka forward pass)\n",
    "# X e Î´ hanno i valori per ogni layer (servono per fare il backward pass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5675bf2f",
   "metadata": {},
   "source": [
    "Adesso possiamo calcolare il gradiente della loss usando la nostra tecnica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd9adda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Matrix{Matrix{Float64}}}:\n",
       " [[-2.814450734892308e-7 4.3426074348366277e-7 â€¦ 5.3993442984768135e-8 -1.2440168841931427e-7; -2.2324787182547127e-7 3.444644695462312e-7 â€¦ 4.282879075265714e-8 -9.867760752209884e-8; 6.036549800473476e-8 -9.314203016234517e-8 â€¦ -1.1580688125966708e-8 2.668219502636078e-8; -2.537333597162168e-7 3.915027214543847e-7 â€¦ 4.867679903538771e-8 -1.1215334521222997e-7]; [3.156391409253484e-5; 2.5037115826100512e-5; -6.769963414364388e-6; 2.8456069333253785e-5;;];;]\n",
       " [[-1.350483245754944e-6 -6.155963518126995e-6 -2.413542258846797e-5 -1.118519359479782e-5; 5.578578001670574e-7 2.5429062907237735e-6 9.969863771461106e-6 4.620381343698259e-6; 5.140213766793724e-7 2.3430848812544036e-6 9.186432557748002e-6 4.257312096971553e-6]; [-0.0023148954734964725; 0.0009562373491668119; 0.000881096283734965;;];;]\n",
       " [[-0.0009572917471781855 0.0009937139646240731 -0.00011036357326805235]; [-0.10683827257852258;;];;]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## The diagonal matrix\n",
    "#M = Diagonal([ [â„‹(Î´[i]) âˆ˜ â„›(X[i-1])  â„‹(Î´[i])] for i=1:N]) # OLD!\n",
    "M = Diagonal([ [â„‹(Î´[i]) âˆ˜ â„›(X[i-1])  â„‹(Î´[i]) âˆ˜ â„›(ones(1,k))] for i=1:N])\n",
    "\n",
    "## The lower triangular matrix (I-L)\n",
    "ImL = Bidiagonal([â„() for i in 1:N], -[â„‹(Î´[i]) âˆ˜ â„’(Ws_and_bs[i][1]) for i=2:N] , :L)\n",
    "\n",
    "## derivata della loss (rispetto all'output layer)\n",
    "g = [ fill(ğ’ª(),N-1) ; [ğ“â€²(X[N],y)] ]      \n",
    "\n",
    "## Finalmente, il gradiente della loss, usando il backslash\n",
    "âˆ‡J = M' * (ImL' \\ g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cc58cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âˆ‡J[1]\n",
      "\tTipo: Matrix{Matrix{Float64}}\t size: (2, 1)\n",
      "\t\tâˆ‡J[1][1] ha dimensione (4, 5), e n_1 x n_0 = 4x5. Tipo Matrix{Float64}\n",
      "\t\tâˆ‡J[1][2] ha dimensione (4, 1), e n_1 \t   = 4.   Tipo Matrix{Float64}\n",
      "\n",
      "âˆ‡J[2]\n",
      "\tTipo: Matrix{Matrix{Float64}}\t size: (2, 1)\n",
      "\t\tâˆ‡J[2][1] ha dimensione (3, 4), e n_2 x n_1 = 3x4. Tipo Matrix{Float64}\n",
      "\t\tâˆ‡J[2][2] ha dimensione (3, 1), e n_2 \t   = 3.   Tipo Matrix{Float64}\n",
      "\n",
      "âˆ‡J[3]\n",
      "\tTipo: Matrix{Matrix{Float64}}\t size: (2, 1)\n",
      "\t\tâˆ‡J[3][1] ha dimensione (1, 3), e n_3 x n_2 = 1x3. Tipo Matrix{Float64}\n",
      "\t\tâˆ‡J[3][2] ha dimensione (1, 1), e n_3 \t   = 1.   Tipo Matrix{Float64}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i=1:N\n",
    "    print(\"âˆ‡J[$i]\\n\")\n",
    "    print(\"\\tTipo: $(typeof(âˆ‡J[i]))\\t size: $(size(âˆ‡J[i]))\\n\")\n",
    "    print(\"\\t\\tâˆ‡J[$i][1] ha dimensione $(size(âˆ‡J[i][1])), e n_$(i) x n_$(i-1) = $(n[i+1])x$(n[i]). Tipo $(typeof(âˆ‡J[i][1]))\\n\")\n",
    "    print(\"\\t\\tâˆ‡J[$i][2] ha dimensione $(size(âˆ‡J[i][2])), e n_$(i) \\t   = $(n[i+1]).   Tipo $(typeof(âˆ‡J[i][2]))\\n\")\n",
    "    print(\"\\n\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a491fb",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b298ae79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flatten (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# flatten(J) = vcat((x->x[:]).(vcat(J...))...)\n",
    "\n",
    "function flatten(J) \n",
    "    # create a 2N x 1 matrix of matrices [Wâ‚; Bâ‚; ... Wâ‚™]\n",
    "    stackedWandB = vcat(J...)       # this is a Matrix{Matrix{Float64}}\n",
    "    # flatten out the matrices inside the stack\n",
    "    unstackedStack = (x->x[:]).(stackedWandB)   # this is a Matrix{Vector{Float64}}\n",
    "\n",
    "    # stack all the vectors that are in the `unstackedStack` matrix\n",
    "    return vcat(unstackedStack...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "72b07567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|| âˆ‡J || = 0.10688023889755821\n"
     ]
    }
   ],
   "source": [
    "print(\"|| âˆ‡J || = $(norm(flatten(âˆ‡J)))\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fce4328",
   "metadata": {},
   "source": [
    "Calcoliamo il gradiente usando il metodo delle differenze finite, per controllare il risultato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "20933c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#âˆ‡Jfd is the gradient calculated with finite differences method\n",
    "\n",
    "# creiamo uno zero della stessa dimensione del gradiente\n",
    "âˆ‡Jfd = Ws_and_bs*0\n",
    "Ïµ = Ws_and_bs*0\n",
    "#ğœ€ = .0001\n",
    "ğœ€ = âˆšeps() #* norm(flatten(âˆ‡J))\n",
    "for i=1:length(Ws_and_bs), wb=1:2\n",
    "    for j=1:length(Ïµ[i][wb])    \n",
    "        Ïµ[i][wb][j] = ğœ€\n",
    "        # Derivata direzionale approssimata con differenze finite\n",
    "        âˆ‡Jfd[i][wb][j] = (ğ“(neural_net(Ws_and_bs+Ïµ,Xâ‚€)[1][N],y) .- ğ“(neural_net(Ws_and_bs-Ïµ,Xâ‚€)[1][N],y)) / (2ğœ€)\n",
    "        Ïµ[i][wb][j] = .0\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f0156165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âˆ‡Jfd[1]\n",
      "\tTipo: Vector{Array{Float64}}\t size: (2,)\n",
      "\t\tâˆ‡Jfd[1][1] ha dimensione (4, 5), e n_1 x n_0 = 4x5. Tipo Matrix{Float64}\n",
      "\t\tâˆ‡Jfd[1][2] ha dimensione (4,)  , e n_1 \t     = 4.   Tipo Vector{Float64}\n",
      "\n",
      "âˆ‡Jfd[2]\n",
      "\tTipo: Vector{Array{Float64}}\t size: (2,)\n",
      "\t\tâˆ‡Jfd[2][1] ha dimensione (3, 4), e n_2 x n_1 = 3x4. Tipo Matrix{Float64}\n",
      "\t\tâˆ‡Jfd[2][2] ha dimensione (3,)  , e n_2 \t     = 3.   Tipo Vector{Float64}\n",
      "\n",
      "âˆ‡Jfd[3]\n",
      "\tTipo: Vector{Array{Float64}}\t size: (2,)\n",
      "\t\tâˆ‡Jfd[3][1] ha dimensione (1, 3), e n_3 x n_2 = 1x3. Tipo Matrix{Float64}\n",
      "\t\tâˆ‡Jfd[3][2] ha dimensione (1,)  , e n_3 \t     = 1.   Tipo Vector{Float64}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i=1:N\n",
    "    print(\"âˆ‡Jfd[$i]\\n\")\n",
    "    print(\"\\tTipo: $(typeof(âˆ‡Jfd[i]))\\t size: $(size(âˆ‡Jfd[i]))\\n\")\n",
    "    print(\"\\t\\tâˆ‡Jfd[$i][1] ha dimensione $(size(âˆ‡Jfd[i][1])), e n_$(i) x n_$(i-1) = $(n[i+1])x$(n[i]). Tipo $(typeof(âˆ‡Jfd[i][1]))\\n\")\n",
    "    print(\"\\t\\tâˆ‡Jfd[$i][2] ha dimensione $(size(âˆ‡Jfd[i][2]))  , e n_$(i) \\t     = $(n[i+1]).   Tipo $(typeof(âˆ‡Jfd[i][2]))\\n\")\n",
    "    print(\"\\n\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c01f3b",
   "metadata": {},
   "source": [
    "Interessante notare un leggero mismatch di tipi tra `âˆ‡J` e `âˆ‡Jfd`, ma restano compatibili. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f48e3d4",
   "metadata": {},
   "source": [
    "Vediamo l'errore assoluto e l'errore relativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "469f49cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||âˆ‡J - âˆ‡Jfd|| = 5.0046585346007955e-11\n",
      "||âˆ‡J - âˆ‡Jfd|| / ||âˆ‡J|| = 4.682491905166514e-10\n"
     ]
    }
   ],
   "source": [
    "print(\"||âˆ‡J - âˆ‡Jfd|| = $(norm(flatten(âˆ‡J)-flatten(âˆ‡Jfd)))\\n\")\n",
    "print(\"||âˆ‡J - âˆ‡Jfd|| / ||âˆ‡J|| = $(norm(flatten(âˆ‡J)-flatten(âˆ‡Jfd)) / norm(flatten(âˆ‡J)))\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2425ea3f",
   "metadata": {},
   "source": [
    "Il fatto che l'errore sia molto piccolo suggerisce che il calcolo del gradiente di `J` tramite soluzione del sistema lineare sia corretto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90642cba",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c8c1c4c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e2f9a82",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8f1ff64",
   "metadata": {},
   "source": [
    "## Errori, e problemi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b243bfc2",
   "metadata": {},
   "source": [
    "### In generale, moltiplicazione tra matrici di operatori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bbb5e4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ef6035",
   "metadata": {},
   "source": [
    "### Moltiplicare matrici di operatori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4075ac",
   "metadata": {},
   "source": [
    "E' possibile moltiplicare ($\\equiv$ comporre) matrici di operatori, usando le regole a nostra disposizione? E eventualmente aggiungendone di nuove?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed9d2a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3Ã—3 Diagonal{Operator, Vector{Operator}}:\n",
       " â„‹(4, 10)âˆ˜â„›(5, 10)  â‹…                  â‹…\n",
       " â‹…                  â„‹(3, 10)âˆ˜â„›(4, 10)  â‹…\n",
       " â‹…                  â‹…                  â„‹(1, 10)âˆ˜â„›(3, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Mnuova = Diagonal([â„‹(Î´[i]) âˆ˜ â„›(X[i-1]) for i=1:N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6782f45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3Ã—3 Bidiagonal{Operator, Vector{Operator}}:\n",
       " Iâˆ˜â„‹(4, 10)âˆ˜â„›(5, 10)                  â€¦  â‹…\n",
       " -â„‹(3, 10)âˆ˜â„’(3, 4)âˆ˜â„‹(4, 10)âˆ˜â„›(5, 10)     â‹…\n",
       " â‹…                                       Iâˆ˜â„‹(1, 10)âˆ˜â„›(3, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try\n",
    "    ImL * Mnuova\n",
    "catch e\n",
    "    showerror(stdout, e)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d40f06c",
   "metadata": {},
   "source": [
    "Come glielo spieghiamo che quell'elemento lÃ¬ in realtÃ  Ã¨ zero??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e4e1bc",
   "metadata": {},
   "source": [
    "**AGGIUSTARE**: Dando le martellate giuste, qualcosa si puÃ² fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79c2ff10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "* (generic function with 191 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "*(A::Operator, B::Operator) = A âˆ˜ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5ee7d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+ (generic function with 193 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "+(A::Operator, B::Operator) = Operator(X->(A.op(X) + B.op(X)), X->(A.adj(X) + B.adj(X)), A.sym*\" + \"*B.sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63879d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3Ã—3 Matrix{Operator}:\n",
       " ğ’ªâˆ˜ğ’ª + ğ’ªâˆ˜ğ’ª + Iâˆ˜â„‹(4, 10)âˆ˜â„›(5, 10) + ğ’ª                  â€¦  ğ’ªâˆ˜â„‹(1, 10)âˆ˜â„›(3, 10) + ğ’ªâˆ˜ğ’ª + Iâˆ˜ğ’ª + ğ’ª\n",
       " ğ’ªâˆ˜ğ’ª + Iâˆ˜ğ’ª + -â„‹(3, 10)âˆ˜â„’(3, 4)âˆ˜â„‹(4, 10)âˆ˜â„›(5, 10) + ğ’ª     ğ’ªâˆ˜â„‹(1, 10)âˆ˜â„›(3, 10) + Iâˆ˜ğ’ª + -â„‹(3, 10)âˆ˜â„’(3, 4)âˆ˜ğ’ª + ğ’ª\n",
       " Iâˆ˜ğ’ª + -â„‹(1, 10)âˆ˜â„’(1, 3)âˆ˜ğ’ª + ğ’ªâˆ˜â„‹(4, 10)âˆ˜â„›(5, 10) + ğ’ª     Iâˆ˜â„‹(1, 10)âˆ˜â„›(3, 10) + -â„‹(1, 10)âˆ˜â„’(1, 3)âˆ˜ğ’ª + ğ’ªâˆ˜ğ’ª + ğ’ª"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Matrix(ImL) * Matrix(Mnuova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6aae243",
   "metadata": {},
   "outputs": [
    {
     "ename": "DimensionMismatch",
     "evalue": "DimensionMismatch: incompatible dimensions for matrix multiplication: tried to multiply a matrix of size (3, 4) with a matrix of size (1, 2). The second dimension of the first matrix: 4, does not match the first dimension of the second matrix: 1.",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch: incompatible dimensions for matrix multiplication: tried to multiply a matrix of size (3, 4) with a matrix of size (1, 2). The second dimension of the first matrix: 4, does not match the first dimension of the second matrix: 1.\n",
      "\n",
      "Stacktrace:\n",
      "  [1] matmul_size_check_error(sizeA::Tuple{Int64, Int64}, sizeB::Tuple{Int64, Int64})\n",
      "    @ LinearAlgebra ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:431\n",
      "  [2] matmul_size_check\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:418 [inlined]\n",
      "  [3] matmul_size_check\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:441 [inlined]\n",
      "  [4] _generic_matmatmul!(C::Matrix{Union{}}, A::Matrix{Float64}, B::Matrix{Operator}, alpha::Bool, beta::Bool)\n",
      "    @ LinearAlgebra ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:1018\n",
      "  [5] generic_matmatmul!\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:1009 [inlined]\n",
      "  [6] generic_matmatmul_wrapper!\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:343 [inlined]\n",
      "  [7] _mul!\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:328 [inlined]\n",
      "  [8] mul!\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:297 [inlined]\n",
      "  [9] mul!\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:265 [inlined]\n",
      " [10] mul\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:118 [inlined]\n",
      " [11] *\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:114 [inlined]\n",
      " [12] #â„’##0\n",
      "    @ ~/Scrivania/MA-project/Codice/src/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W3sZmlsZQ==.jl:10 [inlined]\n",
      " [13] call_composed\n",
      "    @ ./operators.jl:1100 [inlined]\n",
      " [14] call_composed\n",
      "    @ ./operators.jl:1099 [inlined]\n",
      " [15] (::ComposedFunction{var\"#â„‹##0#â„‹##1\"{Matrix{Float64}}, var\"#â„’##0#â„’##1\"{Matrix{Float64}}})(x::Matrix{Operator}; kw::@Kwargs{})\n",
      "    @ Base ./operators.jl:1096\n",
      " [16] (::var\"#-##0#-##1\"{Operator})(X::Matrix{Operator})\n",
      "    @ Main ~/Scrivania/MA-project/Codice/src/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W5sZmlsZQ==.jl:8\n",
      " [17] *(A::Operator, X::Matrix{Operator})\n",
      "    @ Main ~/Scrivania/MA-project/Codice/src/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W5sZmlsZQ==.jl:11\n",
      " [18] _mul!(C::Bidiagonal{Any, Vector{Any}}, A::Bidiagonal{Operator, Vector{Operator}}, B::Diagonal{Matrix{Operator}, Vector{Matrix{Operator}}}, _add::LinearAlgebra.MulAddMul{true, true, Bool, Bool})\n",
      "    @ LinearAlgebra ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/bidiag.jl:920\n",
      " [19] macro expansion\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/generic.jl:100 [inlined]\n",
      " [20] _mul!\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/bidiag.jl:831 [inlined]\n",
      " [21] mul!\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:297 [inlined]\n",
      " [22] mul!\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:265 [inlined]\n",
      " [23] mul\n",
      "    @ ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:118 [inlined]\n",
      " [24] *(A::Bidiagonal{Operator, Vector{Operator}}, B::Diagonal{Matrix{Operator}, Vector{Matrix{Operator}}})\n",
      "    @ LinearAlgebra ~/.julia/juliaup/julia-1.12.4+0.x64.linux.gnu/share/julia/stdlib/v1.12/LinearAlgebra/src/matmul.jl:114\n",
      " [25] top-level scope\n",
      "    @ ~/Scrivania/MA-project/Codice/src/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_Y210sZmlsZQ==.jl:1"
     ]
    }
   ],
   "source": [
    "ImL * M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "534fdf8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.12.4",
   "language": "julia",
   "name": "julia-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
